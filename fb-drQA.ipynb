{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fb-drQA.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"y4_XFnnMGZ09","colab_type":"code","outputId":"77958b08-e450-4a25-f9be-2af3df40f0ee","executionInfo":{"status":"ok","timestamp":1565081103310,"user_tz":-180,"elapsed":22910,"user":{"displayName":"Ancient Colors","photoUrl":"","userId":"07486088927151244582"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!git clone https://github.com/facebookresearch/DrQA.git\n","%cd DrQA \n","!pip install -r requirements.txt\n","!python setup.py develop"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'DrQA'...\n","remote: Enumerating objects: 250, done.\u001b[K\n","remote: Total 250 (delta 0), reused 0 (delta 0), pack-reused 250\u001b[K\n","Receiving objects: 100% (250/250), 559.28 KiB | 8.47 MiB/s, done.\n","Resolving deltas: 100% (117/117), done.\n","/content/DrQA\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.16.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.21.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.1.0)\n","Collecting regex (from -r requirements.txt (line 4))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n","\u001b[K     |████████████████████████████████| 655kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.28.1)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.7.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.3.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n","Collecting elasticsearch (from -r requirements.txt (line 9))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/43/38329621bcca6f0b97e1cc36fb3cef889414a1960fcdc83a41e26b496634/elasticsearch-7.0.2-py2.py3-none-any.whl (83kB)\n","\u001b[K     |████████████████████████████████| 92kB 21.2MB/s \n","\u001b[?25hCollecting pexpect==4.2.1 (from -r requirements.txt (line 10))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/16/4859a0376be8b87bf3920b1f6e63b8a3c0ee42488babee07c87ca9316e03/pexpect-4.2.1-py2.py3-none-any.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 19.8MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (0.13.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 8)) (1.12.0)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect==4.2.1->-r requirements.txt (line 10)) (0.6.0)\n","Building wheels for collected packages: regex\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604131 sha256=6188fd8513d8e8fa90d053597c5f26a1ff2579a9b343fa008c27bd08f50aa545\n","  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n","Successfully built regex\n","Installing collected packages: regex, elasticsearch, pexpect\n","  Found existing installation: pexpect 4.7.0\n","    Uninstalling pexpect-4.7.0:\n","      Successfully uninstalled pexpect-4.7.0\n","Successfully installed elasticsearch-7.0.2 pexpect-4.2.1 regex-2019.6.8\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pexpect"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["running develop\n","running egg_info\n","creating drqa.egg-info\n","writing drqa.egg-info/PKG-INFO\n","writing dependency_links to drqa.egg-info/dependency_links.txt\n","writing requirements to drqa.egg-info/requires.txt\n","writing top-level names to drqa.egg-info/top_level.txt\n","writing manifest file 'drqa.egg-info/SOURCES.txt'\n","writing manifest file 'drqa.egg-info/SOURCES.txt'\n","running build_ext\n","Creating /usr/local/lib/python3.6/dist-packages/drqa.egg-link (link to .)\n","Adding drqa 0.1.0 to easy-install.pth file\n","\n","Installed /content/DrQA\n","Processing dependencies for drqa==0.1.0\n","Searching for pexpect==4.2.1\n","Best match: pexpect 4.2.1\n","Adding pexpect 4.2.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for elasticsearch==7.0.2\n","Best match: elasticsearch 7.0.2\n","Adding elasticsearch 7.0.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for nltk==3.2.5\n","Best match: nltk 3.2.5\n","Adding nltk 3.2.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for scipy==1.3.0\n","Best match: scipy 1.3.0\n","Adding scipy 1.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for prettytable==0.7.2\n","Best match: prettytable 0.7.2\n","Adding prettytable 0.7.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for tqdm==4.28.1\n","Best match: tqdm 4.28.1\n","Adding tqdm 4.28.1 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for regex==2019.6.8\n","Best match: regex 2019.6.8\n","Adding regex 2019.6.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for termcolor==1.1.0\n","Best match: termcolor 1.1.0\n","Adding termcolor 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for scikit-learn==0.21.3\n","Best match: scikit-learn 0.21.3\n","Adding scikit-learn 0.21.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.16.4\n","Best match: numpy 1.16.4\n","Adding numpy 1.16.4 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for ptyprocess==0.6.0\n","Best match: ptyprocess 0.6.0\n","Adding ptyprocess 0.6.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for urllib3==1.24.3\n","Best match: urllib3 1.24.3\n","Adding urllib3 1.24.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.12.0\n","Best match: six 1.12.0\n","Adding six 1.12.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for joblib==0.13.2\n","Best match: joblib 0.13.2\n","Adding joblib 0.13.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for drqa==0.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BaOE7nGQHNtS","colab_type":"text"},"source":["If you do not already have a CoreNLP download you can run:"]},{"cell_type":"code","metadata":{"id":"g1KTnR8LGni0","colab_type":"code","outputId":"a6544871-7bea-464f-c72a-ade0dfac0405","executionInfo":{"status":"ok","timestamp":1565081664188,"user_tz":-180,"elapsed":439277,"user":{"displayName":"Ancient Colors","photoUrl":"","userId":"07486088927151244582"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!bash ./install_corenlp.sh"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Specify download path or enter to use default (data/corenlp): \n","Will download to: data/corenlp\n","/tmp /content/DrQA\n","--2019-08-06 08:47:11--  http://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip [following]\n","--2019-08-06 08:47:12--  https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 390211140 (372M) [application/zip]\n","Saving to: ‘stanford-corenlp-full-2017-06-09.zip’\n","\n","stanford-corenlp-fu 100%[===================>] 372.13M   810KB/s    in 4m 14s  \n","\n","2019-08-06 08:51:26 (1.47 MB/s) - ‘stanford-corenlp-full-2017-06-09.zip’ saved [390211140/390211140]\n","\n","Archive:  stanford-corenlp-full-2017-06-09.zip\n","   creating: stanford-corenlp-full-2017-06-09/\n","  inflating: stanford-corenlp-full-2017-06-09/xom-1.2.10-src.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/CoreNLP-to-HTML.xsl  \n","  inflating: stanford-corenlp-full-2017-06-09/README.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/jollyday-0.4.9-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/LIBRARY-LICENSES  \n","   creating: stanford-corenlp-full-2017-06-09/sutime/\n","  inflating: stanford-corenlp-full-2017-06-09/sutime/defs.sutime.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/sutime/english.sutime.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/sutime/english.holidays.sutime.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-javadoc.jar  \n"," extracting: stanford-corenlp-full-2017-06-09/ejml-0.23-src.zip  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-models.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/input.txt.xml  \n","  inflating: stanford-corenlp-full-2017-06-09/build.xml  \n","  inflating: stanford-corenlp-full-2017-06-09/pom.xml  \n","   creating: stanford-corenlp-full-2017-06-09/tokensregex/\n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.input.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/retokenize.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.properties  \n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.rules.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/javax.json-api-1.0-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/protobuf.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/StanfordDependenciesManual.pdf  \n","   creating: stanford-corenlp-full-2017-06-09/patterns/\n","  inflating: stanford-corenlp-full-2017-06-09/patterns/example.properties  \n"," extracting: stanford-corenlp-full-2017-06-09/patterns/otherpeople.txt  \n"," extracting: stanford-corenlp-full-2017-06-09/patterns/goldplaces.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/stopwords.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/presidents.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/names.txt  \n"," extracting: stanford-corenlp-full-2017-06-09/patterns/places.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/goldnames.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/slf4j-simple.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/input.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/joda-time.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/xom.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/StanfordCoreNlpDemo.java  \n","  inflating: stanford-corenlp-full-2017-06-09/slf4j-api.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/ejml-0.23.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/javax.json.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/Makefile  \n","  inflating: stanford-corenlp-full-2017-06-09/corenlp.sh  \n","  inflating: stanford-corenlp-full-2017-06-09/joda-time-2.9-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/jollyday.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/ShiftReduceDemo.java  \n","  inflating: stanford-corenlp-full-2017-06-09/SemgrexDemo.java  \n","  inflating: stanford-corenlp-full-2017-06-09/LICENSE.txt  \n","/content/DrQA\n","Add to ~/.bashrc CLASSPATH (recommended)? [yes/no]: y\n","Please answer yes or no.\n","Add to ~/.bashrc CLASSPATH (recommended)? [yes/no]: yes\n","\n","*** NOW RUN: ***\n","\n","export CLASSPATH=$CLASSPATH:data/corenlp/*\n","\n","****************\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BgTngBlEKHM8","colab_type":"code","outputId":"fc6cca25-5467-44f1-e95d-9b34dcf6d8b7","executionInfo":{"status":"ok","timestamp":1565082029827,"user_tz":-180,"elapsed":1864,"user":{"displayName":"Ancient Colors","photoUrl":"","userId":"07486088927151244582"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["#Check Java version\n","!java -version"],"execution_count":0,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.3\" 2019-04-16\n","OpenJDK Runtime Environment (build 11.0.3+7-Ubuntu-1ubuntu218.04.1)\n","OpenJDK 64-Bit Server VM (build 11.0.3+7-Ubuntu-1ubuntu218.04.1, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6uiljkkxRExz","colab_type":"text"},"source":["Point to real classpath"]},{"cell_type":"code","metadata":{"id":"WFKmUWZFLOYb","colab_type":"code","colab":{}},"source":["import drqa.tokenizers\n","drqa.tokenizers.set_default('corenlp_classpath', '/content/DrQA/data/corenlp/*')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1aHAyhxSHOxN","colab_type":"text"},"source":["Verify that it runs:"]},{"cell_type":"code","metadata":{"id":"-rCw8xSGHJNo","colab_type":"code","outputId":"206b080f-d728-459e-fb0f-e08c8133f5a6","executionInfo":{"status":"ok","timestamp":1565082337467,"user_tz":-180,"elapsed":1762,"user":{"displayName":"Ancient Colors","photoUrl":"","userId":"07486088927151244582"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from drqa.tokenizers import CoreNLPTokenizer\n","CoreNLPTokenizer().tokenize('one two three').words()  # Should complete immediately"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['one', 'two', 'three']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"651rrWfUHV7D","colab_type":"text"},"source":["To download all provided trained models and data for Wikipedia question answering, run:"]},{"cell_type":"code","metadata":{"id":"bEV8EEasHKTK","colab_type":"code","outputId":"c9322bc9-18b5-4114-c613-c4992973bdf6","executionInfo":{"status":"ok","timestamp":1565083061158,"user_tz":-180,"elapsed":710654,"user":{"displayName":"Ancient Colors","photoUrl":"","userId":"07486088927151244582"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!bash ./download.sh"],"execution_count":0,"outputs":[{"output_type":"stream","text":["DRQA_DATA not set; downloading to default path ('data').\n","--2019-08-06 09:05:51--  https://dl.fbaipublicfiles.com/drqa/data.tar.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:16a6, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8104538193 (7.5G) [application/x-tar]\n","Saving to: ‘./data.tar.gz’\n","\n","./data.tar.gz       100%[===================>]   7.55G  27.9MB/s    in 4m 38s  \n","\n","2019-08-06 09:10:29 (27.8 MB/s) - ‘./data.tar.gz’ saved [8104538193/8104538193]\n","\n","data/\n","data/datasets/\n","data/datasets/CuratedTrec-test.txt\n","data/datasets/CuratedTrec-train.txt\n","data/datasets/WikiMovies-entities.txt\n","data/datasets/WikiMovies-test.txt\n","data/datasets/WikiMovies-train.txt\n","data/reader/\n","data/reader/multitask.mdl\n","data/reader/single.mdl\n","data/wikipedia/\n","data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz\n","data/wikipedia/docs.db\n","--2019-08-06 09:17:33--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.108.153, 185.199.111.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30288272 (29M) [application/json]\n","Saving to: ‘./data/datasets/SQuAD-v1.1-train.json’\n","\n","./data/datasets/SQu 100%[===================>]  28.88M   109MB/s    in 0.3s    \n","\n","2019-08-06 09:17:34 (109 MB/s) - ‘./data/datasets/SQuAD-v1.1-train.json’ saved [30288272/30288272]\n","\n","--2019-08-06 09:17:35--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.108.153, 185.199.111.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4854279 (4.6M) [application/json]\n","Saving to: ‘./data/datasets/SQuAD-v1.1-dev.json’\n","\n","./data/datasets/SQu 100%[===================>]   4.63M  --.-KB/s    in 0.1s    \n","\n","2019-08-06 09:17:35 (44.0 MB/s) - ‘./data/datasets/SQuAD-v1.1-dev.json’ saved [4854279/4854279]\n","\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  3419    0  3419    0     0  16759      0 --:--:-- --:--:-- --:--:-- 16842\n","--2019-08-06 09:17:36--  http://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.train.json.bz2\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.train.json.bz2 [following]\n","--2019-08-06 09:17:36--  https://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.train.json.bz2\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 100725 (98K) [application/x-bzip2]\n","Saving to: ‘./data/datasets/WebQuestions-train.json.bz2’\n","\n","./data/datasets/Web 100%[===================>]  98.36K   358KB/s    in 0.3s    \n","\n","2019-08-06 09:17:37 (358 KB/s) - ‘./data/datasets/WebQuestions-train.json.bz2’ saved [100725/100725]\n","\n","--2019-08-06 09:17:37--  http://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.test.json.bz2\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.test.json.bz2 [following]\n","--2019-08-06 09:17:37--  https://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.test.json.bz2\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 60689 (59K) [application/x-bzip2]\n","Saving to: ‘./data/datasets/WebQuestions-test.json.bz2’\n","\n","./data/datasets/Web 100%[===================>]  59.27K   287KB/s    in 0.2s    \n","\n","2019-08-06 09:17:38 (287 KB/s) - ‘./data/datasets/WebQuestions-test.json.bz2’ saved [60689/60689]\n","\n","--2019-08-06 09:17:38--  https://dl.fbaipublicfiles.com/drqa/freebase-entities.txt.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:16a6, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16063580 (15M) [text/plain]\n","Saving to: ‘./data/datasets/freebase-entities.txt.gz’\n","\n","./data/datasets/fre 100%[===================>]  15.32M  15.6MB/s    in 1.0s    \n","\n","2019-08-06 09:17:40 (15.6 MB/s) - ‘./data/datasets/freebase-entities.txt.gz’ saved [16063580/16063580]\n","\n","DrQA download done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vPmylJqQH15L","colab_type":"text"},"source":["Run python scripts/pipeline/interactive.py to drop into an interactive session. For each question, the top span and the Wikipedia paragraph it came from are returned."]},{"cell_type":"code","metadata":{"id":"32Sa_eDHH2BI","colab_type":"code","outputId":"9da73e00-d636-4207-b20f-8295989175b0","executionInfo":{"status":"ok","timestamp":1565083400735,"user_tz":-180,"elapsed":88594,"user":{"displayName":"Ancient Colors","photoUrl":"","userId":"07486088927151244582"}},"colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["!python scripts/pipeline/interactive.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["08/06/2019 09:21:58 AM: [ CUDA enabled (GPU -1) ]\n","08/06/2019 09:21:58 AM: [ Initializing pipeline... ]\n","08/06/2019 09:21:58 AM: [ Initializing document ranker... ]\n","08/06/2019 09:21:58 AM: [ Loading /content/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x4128000 @  0x7f4be6ddd1e7 0x7f4be4926ca1 0x7f4be498b778 0x7f4be492a4a1 0x53edb5 0x57ec0c 0x4f88ba 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f4065 0x5a1481 0x57c2fe 0x545708 0x4f9ba9 0x4f7a28 0x4f876d 0x4f98c7 0x4f6128 0x4f426e 0x5a1481 0x512a60 0x53ee21 0x57c2fe 0x4facb1 0x4f6128 0x4f426e 0x5a1481 0x512a60\n","tcmalloc: large alloc 4253114368 bytes == 0x7f4a327ea000 @  0x7f4be6ddd1e7 0x7f4be4926ca1 0x7f4be498b778 0x7f4be492a4a1 0x53edb5 0x57ec0c 0x4f88ba 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f4065 0x5a1481 0x57c2fe 0x545708 0x4f9ba9 0x4f7a28 0x4f876d 0x4f98c7 0x4f6128 0x4f426e 0x5a1481 0x512a60 0x53ee21 0x57c2fe 0x4facb1 0x4f6128 0x4f426e 0x5a1481 0x512a60\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7OYFpXExQ5Ri","colab_type":"text"},"source":["\"Wikipedia-based models have significant storage and RAM requirements, therefore it's impossible to interact with them on Colab\" :("]}]}